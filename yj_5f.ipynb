{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "cfgaHf4PSXp0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26759370-1e7a-4807-c055-4df58da54b3d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "import torch\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "t4637JOOOUzs"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#파일 삭제\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "def delete_files_in_folder(folder_path):\n",
        "    # 폴더 안의 파일들을 리스트로 가져옵니다.\n",
        "    file_list = os.listdir(folder_path)\n",
        "\n",
        "    # 리스트에 있는 파일들을 하나씩 삭제합니다.\n",
        "    for file_name in file_list:\n",
        "        file_path = os.path.join(folder_path, file_name)\n",
        "        if os.path.isfile(file_path):\n",
        "            os.remove(file_path)\n",
        "        elif os.path.isdir(file_path):\n",
        "            shutil.rmtree(file_path)\n",
        "\n",
        "# 폴더 경로 설정\n",
        "target_folder = \"/content/drive/MyDrive/google_da\"  # 여기에 삭제하고자 하는 폴더의 경로를 입력하세요.\n",
        "\n",
        "# 폴더 안의 파일들을 삭제합니다.\n",
        "delete_files_in_folder(target_folder)"
      ],
      "metadata": {
        "id": "15VcHOTeS0M-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "outputId": "52ad6e25-2015-4f16-fc4e-5b37cde72708"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-209f6047e32f>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# 폴더 안의 파일들을 삭제합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mdelete_files_in_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-209f6047e32f>\u001b[0m in \u001b[0;36mdelete_files_in_folder\u001b[0;34m(folder_path)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdelete_files_in_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# 폴더 안의 파일들을 리스트로 가져옵니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mfile_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# 리스트에 있는 파일들을 하나씩 삭제합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/google_da'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#day 파일 개수 세기\n",
        "\n",
        "import os\n",
        "\n",
        "def count_files_in_folder(folder_path):\n",
        "    file_count = 0\n",
        "\n",
        "    for _, _, files in os.walk(folder_path):\n",
        "        file_count += len(files)\n",
        "\n",
        "    return file_count\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    folder_path = '/content/drive/MyDrive/night_1'  # 파일 개수를 세고자 하는 폴더 경로를 입력하세요.\n",
        "\n",
        "    num_files = count_files_in_folder(folder_path)\n",
        "    print(f'폴더 \"{folder_path}\" 내에 있는 파일 개수: {num_files}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCNQE3yXN6lh",
        "outputId": "17b6d08a-9970-4628-ca28-189cab21edf4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "폴더 \"/content/drive/MyDrive/night_1\" 내에 있는 파일 개수: 908\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ew9dCwRLQuhN"
      },
      "outputs": [],
      "source": [
        "#시작\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "import numpy as np\n",
        "import torch\n",
        "class BaseAugmentation:\n",
        "    def __init__(self, mean=[0.5, 0.5, 0.5], std=[0.5,0.5,0.5]):\n",
        "        self.transform = A.Compose([\n",
        "                A.Normalize(mean=mean, std=std, always_apply=True),\n",
        "                ToTensorV2()\n",
        "        ])\n",
        "#A.augmentations.crops.transforms.RandomCrop(128, 128, always_apply=False,p=1.0)\n",
        "def denormalize_image(image, mean=[0.5, 0.5, 0.5], std=[0.5,0.5,0.5]):\n",
        "\n",
        "    mean = torch.tensor(np.array(mean).reshape(1,-1,1,1))\n",
        "    std = torch.tensor(np.array(std).reshape(1,-1,1,1))\n",
        "\n",
        "    # if len(image.shape) == 4 and image.shape[0]==16:\n",
        "    #     image = image.squeeze()\n",
        "\n",
        "    denorm_image = (image*std+mean).clamp_(0,1)\n",
        "\n",
        "    return denorm_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "fz5JTZ_N_i1o"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "class AdversarialLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AdversarialLoss, self).__init__()\n",
        "        self.loss = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    # generator\n",
        "    def forward_G(self, d_g_x, real):\n",
        "        return self.loss(d_g_x, real)\n",
        "\n",
        "    # discriminator\n",
        "    def forward_D(self, d_y ,real, d_g_x, fake):\n",
        "\n",
        "        d_real_loss = self.loss(d_y, real)\n",
        "        d_fake_loss = self.loss(d_g_x, fake)\n",
        "        d_loss = (d_real_loss + d_fake_loss)/2\n",
        "        return d_loss\n",
        "\n",
        "\n",
        "class CycleConsistencyLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CycleConsistencyLoss, self).__init__()\n",
        "        self.loss_forward = nn.L1Loss()\n",
        "        self.loss_backward = nn.L1Loss()\n",
        "\n",
        "    def forward(self, x, y, f_g_x, g_f_y):\n",
        "\n",
        "        loss_cyc = self.loss_forward(f_g_x, x) + self.loss_backward(g_f_y, y)\n",
        "\n",
        "        return loss_cyc\n",
        "\n",
        "class IdentityLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(IdentityLoss, self).__init__()\n",
        "        self.loss_x = nn.L1Loss()\n",
        "        self.loss_y = nn.L1Loss()\n",
        "\n",
        "    def forward(self, x, y, f_y, g_x):\n",
        "        loss_idt = self.loss_x(f_y, x) + self.loss_y(g_x, y)\n",
        "\n",
        "        return loss_idt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "lJ8EbHTW_mo2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import cv2\n",
        "import random\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from typing import List, Dict\n",
        "\n",
        "\n",
        "class UnalignedDataset(Dataset):\n",
        "\n",
        "    def __init__(self, data_root_A: str, data_root_B: str, is_train:bool=True, transforms=ToTensorV2(), num_workers: int=2):\n",
        "\n",
        "        super(UnalignedDataset, self).__init__()\n",
        "        self.data_root_A = data_root_A\n",
        "        self.data_root_B = data_root_B\n",
        "        self.is_train = is_train\n",
        "        self.transforms = transforms\n",
        "\n",
        "        paths_A = sorted(self._load_image_path(self.data_root_A))\n",
        "        paths_B = sorted(self._load_image_path(self.data_root_B))\n",
        "\n",
        "        self.image_paths_A, self.image_paths_B = self._adjust_dataset_length(paths_A, paths_B)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "\n",
        "        return len(self.image_paths_A)\n",
        "\n",
        "    def __getitem__(self, index:int)->Dict:\n",
        "\n",
        "        A = cv2.cvtColor(cv2.imread(self.image_paths_A[index]), cv2.COLOR_BGR2RGB)\n",
        "        B = cv2.cvtColor(cv2.imread(self.image_paths_B[index]), cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        if self.transforms:\n",
        "            A = self.transforms(image=A)['image']\n",
        "            B = self.transforms(image=B)['image']\n",
        "\n",
        "        return {'A': A, 'B': B}\n",
        "\n",
        "    def _load_image_path(self, data_dir:str)->List[str]:\n",
        "\n",
        "        image_path  = glob.glob(data_dir+\"/*\")\n",
        "\n",
        "        return image_path\n",
        "\n",
        "    def _adjust_dataset_length(self, paths_A:str, paths_B:str):\n",
        "        min_len = min(len(paths_A), len(paths_B))\n",
        "        return paths_A[:min_len], paths_B[:min_len]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "gSj2O5K8_r_T"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from typing import Union\n",
        "from collections import OrderedDict\n",
        "#Generator\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels:int, out_channels:int):\n",
        "\n",
        "        super(ResidualBlock, self).__init__()\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Conv2d(self.in_channels, self.out_channels, kernel_size=3, padding='same', padding_mode='reflect'),\n",
        "            nn.InstanceNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(self.in_channels, self.out_channels, kernel_size=3, padding='same', padding_mode='reflect'),\n",
        "            nn.InstanceNorm2d(self.out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.block(x) + x # skip-connection\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, init_channel:int, kernel_size:int, stride:int, n_blocks:int=6):\n",
        "\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.init_channel=init_channel\n",
        "        self.kernel_size=kernel_size\n",
        "        self.stride=stride\n",
        "        self.n_blocks=n_blocks\n",
        "\n",
        "        layers = OrderedDict()\n",
        "        layers['conv_first'] = self._make_block(in_channels=3, out_channels=self.init_channel, kernel_size=7, stride=1, padding='same') # first layer\n",
        "\n",
        "        # downsampling path (d_k) -> two downsampling blocks\n",
        "        for i in range(2):\n",
        "            ic = self.init_channel*(i+1)\n",
        "            k = 2*ic\n",
        "            layers[f'd_{k}'] = self._make_block(in_channels=ic, out_channels=k, kernel_size=self.kernel_size, stride=self.stride)\n",
        "\n",
        "        # residual block (R_k) -> 6 or 9 blocks\n",
        "        for i in range(self.n_blocks):\n",
        "            layers[f'R{k}_{i+1}'] = ResidualBlock(k, k) # in_channel = out_channel로 동일한 channel dimension 유지\n",
        "\n",
        "        # upsampling path (u_k) -> two upsampling blocks\n",
        "        for i in range(2):\n",
        "            k = int(k/2)\n",
        "            layers[f'u_{k}'] = self._make_block(in_channels=k*2, out_channels=k, kernel_size=self.kernel_size, stride=self.stride, mode='u')\n",
        "\n",
        "        # last conv layer\n",
        "        layers['conv_last'] = nn.Conv2d(in_channels=self.init_channel, out_channels=3, kernel_size=7, stride=1, padding='same', padding_mode='reflect') # last conv layer (to rgb)\n",
        "        layers['tanh'] = nn.Tanh()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            layers\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        op = self.model(x)\n",
        "        assert op.shape == x.shape, f\"output shape ({op.shape}) must be same with the input size ({x.shape})\"\n",
        "        return op\n",
        "\n",
        "    def _make_block(self, in_channels:int, out_channels:int, kernel_size:int, stride:int, padding:Union[int,str]=1, mode:str='d'):\n",
        "\n",
        "\n",
        "        block = []\n",
        "        if mode.lower() == 'd':\n",
        "            block.append(nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, padding_mode='reflect'))\n",
        "\n",
        "        elif mode.lower() == 'u':\n",
        "            block.append(nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=1)) # output size를 input이랑 같게 해주려면 이렇게 설정을 해줄 수밖에 없음.\n",
        "\n",
        "        block += [nn.InstanceNorm2d(out_channels), nn.ReLU(inplace=True)]\n",
        "\n",
        "        return nn.Sequential(*block)\n",
        "\n",
        "\n",
        "#Discriminator\n",
        "\n",
        "shape_dict=dict() # for checking the output's shape\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, n_layers:int=4, input_c:int=3, n_filter:int=64, kernel_size:int=4):\n",
        "\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.model = nn.Sequential()\n",
        "        self.kernel_size=kernel_size\n",
        "        self.n_layers = n_layers\n",
        "        layers = []\n",
        "\n",
        "        # building conv block\n",
        "        for i in range(self.n_layers):\n",
        "            if i == 0:\n",
        "                ic, oc = input_c, n_filter\n",
        "                layers.append(self._make_block(ic, oc, kernel_size=self.kernel_size, stride=2, padding=1, normalize=False))\n",
        "            else:\n",
        "                ic = oc\n",
        "                oc = 2*ic\n",
        "                stride=2\n",
        "\n",
        "                if i == self.n_layers-1: # 마지막 레이어(c512)의 경우, stride=1로 설정할 것.\n",
        "                    stride=1\n",
        "\n",
        "                layers.append(self._make_block(ic, oc, kernel_size=self.kernel_size, stride=stride, padding=1))\n",
        "\n",
        "        # prediction\n",
        "        layers.append(nn.Conv2d(oc, 1, kernel_size=self.kernel_size, stride=1, padding=1))\n",
        "\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "    def _make_block(self, in_channels, out_channels, stride, kernel_size=3, padding=0, normalize=True):\n",
        "        layers = [nn.Conv2d(in_channels=in_channels, out_channels=out_channels, stride=stride, kernel_size=kernel_size, padding=padding)]\n",
        "        if normalize:\n",
        "            layers.append(nn.InstanceNorm2d(out_channels))\n",
        "        layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "# check the output size within a model\n",
        "\n",
        "# hook function은 forward 이후에 activate된다는 점을 잊지 말자.\n",
        "def hook_fn(m, _, o):\n",
        "    shape_dict[m]=o.shape\n",
        "\n",
        "\n",
        "def get_all_layers(net:nn.Module, hook_fn=hook_fn):\n",
        "    for name, layer in net._modules.items():\n",
        "        #print(name)\n",
        "        if isinstance(layer, nn.Sequential):\n",
        "            get_all_layers(layer)\n",
        "        else:\n",
        "            layer.register_forward_hook(hook_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "QgFCZ3_u_u2n"
      },
      "outputs": [],
      "source": [
        "from torch.optim.lr_scheduler import ConstantLR, _LRScheduler, SequentialLR\n",
        "from torch.optim.optimizer import Optimizer\n",
        "import warnings\n",
        "\n",
        "def decay_after_k_epoch(optim: Optimizer, n_epochs:int, init_lr: float, target_lr: float, decay_after:int=100):\n",
        "    scheduler1 = ConstantLR(optim, factor=1, total_iters=decay_after)\n",
        "    scheduler2 = LinearDecayLR(optim, initial_lr = init_lr, target_lr=target_lr, total_iters=n_epochs-decay_after) # constant는 그냥 한 번 줄여주고 마는 거임.\n",
        "\n",
        "    scheduler = SequentialLR(optim, schedulers=[scheduler1, scheduler2], milestones=[decay_after])\n",
        "    return scheduler\n",
        "\n",
        "\n",
        "class LinearDecayLR(_LRScheduler):\n",
        "    def __init__(self, optimizer:Optimizer, initial_lr: float, target_lr:float, total_iters:int, last_epoch:int=-1, verbose:bool=False):\n",
        "\n",
        "        if initial_lr < 0:\n",
        "            raise ValueError(\"Initial Learning rate expected to be a non-negative integer.\")\n",
        "\n",
        "        if target_lr < 0:\n",
        "            raise ValueError(\"Target Learning rate expected to be a non-negative integer.\")\n",
        "\n",
        "        if target_lr > initial_lr:\n",
        "            raise ValueError(\"Target Learning Rate must be larger than Initial Learning Rate.\")\n",
        "\n",
        "        self.init_lr = initial_lr\n",
        "        self.target_lr = target_lr\n",
        "        self.total_iters = total_iters\n",
        "        self.subtract_lr = self._get_decay_constant()\n",
        "\n",
        "        super(LinearDecayLR, self).__init__(optimizer, last_epoch, verbose) # 부모클래스의 init에 필요한 arg 넘겨줌.\n",
        "        # super init을 해도 self.base_lrs를 왜 상속을 못받는 거지?\n",
        "        # 여기서 부모 메소드 init 과정에서 self.get_lr을 호출함. 근데 get_lr에는 self.subtract_lr이 들어가 있고, 그건 다시 부모클래스 init이 \"완료\"되어야 하기 때문에\n",
        "        # 아래 명령을 실행한 적이 없음. 그래서 계속 그런 attribute이 없다고 뜨는 거임.\n",
        "\n",
        "\n",
        "    def _get_decay_constant(self):\n",
        "        return float((self.init_lr-self.target_lr)/self.total_iters)\n",
        "\n",
        "    def get_lr(self):\n",
        "        if not self._get_lr_called_within_step:\n",
        "            warnings.warn(\"To get the learning rate computed by the scheduler, \"\n",
        "                        \"please use 'get_last_lr()'.\", UserWarning)\n",
        "\n",
        "        return [group['lr']-self.subtract_lr for group in self.optimizer.param_groups]\n",
        "\n",
        "\n",
        "class DelayedLinearDecayLR(LinearDecayLR):\n",
        "    def __init__(self, optimizer:Optimizer, initial_lr: float, target_lr: float, total_iters:int, last_epoch:int=-1, decay_after:int=100, verbose:bool=False):\n",
        "        self.decay_after = decay_after\n",
        "\n",
        "        super(DelayedLinearDecayLR, self).__init__(optimizer, initial_lr, target_lr, total_iters, last_epoch, verbose)\n",
        "\n",
        "\n",
        "    def get_lr(self):\n",
        "        if not self._get_lr_called_within_step:\n",
        "            warnings.warn(\"To get the learning rate computed by the scheduler, \"\n",
        "                        \"please use 'get_last_lr()'.\", UserWarning)\n",
        "\n",
        "        if self.decay_after <= self.last_epoch < (self.decay_after + self.total_iters): # 여기에 total iter도 고려해줘야함.\n",
        "            return [group['lr']-self.subtract_lr for group in self.optimizer.param_groups]\n",
        "\n",
        "        else:\n",
        "            return [group['lr'] for group in self.optimizer.param_groups]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "uNJ5l4JN_xdT"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "from torch.optim.optimizer import Optimizer\n",
        "from torch.optim.lr_scheduler import _LRScheduler\n",
        "from typing import Optional\n",
        "from torchvision.utils import make_grid\n",
        "import torchvision.transforms.functional as TF\n",
        "import math\n",
        "\n",
        "#from augmentation_my import denormalize_image\n",
        "\n",
        "def fix_seed(random_seed):\n",
        "    torch.manual_seed(random_seed)\n",
        "    torch.cuda.manual_seed(random_seed)\n",
        "    torch.cuda.manual_seed_all(random_seed)  # if use multi-GPU\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    np.random.seed(random_seed)\n",
        "    random.seed(random_seed)\n",
        "\n",
        "def parse_opt():\n",
        "    opt=argparse.Namespace(\n",
        "        is_train=True,\n",
        "        num_threads=1,\n",
        "        gpu_id=0,\n",
        "        random_seed=0,\n",
        "        data_root_A=\"/content/drive/MyDrive/day_1\",\n",
        "        data_root_B=\"/content/drive/MyDrive/night_1\",\n",
        "        batch_size=8,\n",
        "        n_epochs=4,\n",
        "        beta1=.5,\n",
        "        lr=.0002,\n",
        "        decay_after=100,\n",
        "        target_lr=0.0,\n",
        "        total_iters=100,\n",
        "        lr_decay_verbose=False,\n",
        "        lambda_cyc=10.0,\n",
        "        lambda_idt=0.5,\n",
        "        prj_name=\"cycle_gan\",\n",
        "        exp_name=\"exp1\",\n",
        "        log_interval=25,\n",
        "        sample_save_dir=\"/content/drive/MyDrive/result\", #각 epoch.jpg가 저장되는 곳\n",
        "        checkpoint_dir=\"/content/drive/MyDrive/save_folder\", #epoch.pth가 저장되는 곳\n",
        "        load_epoch=0, #n_epochs 즉 맨 마지막 epoch의 값이 기본값이고, 얼리스탑 기능이 작동하면 값이 변하고 그 값의 폴더를 사용해서 테스트한다.\n",
        "        last_epoch=0, # 다시 시작할때 0값을 마지막 폴더의 숫자로 바꾸고 시작\n",
        "        resume_from = False, # True는 불러올 데이터가 있을때, 즉 이걸 돌리다가 불가피하게 끊겼을때 다시 돌릴 수 있게 하는 것. 그러므로 처음 할 때는 False로 해야함\n",
        "        data_root_A_final=\"/content/drive/MyDrive/cameraday\", #테스트 낮 폴더\n",
        "        data_root_B_final=\"/content/drive/MyDrive/cameranight\" #테스트 밤 폴더\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        )\n",
        "    return opt\n",
        "\n",
        "def save_image(image:torch.Tensor, save_path:str, denormalize:bool=True):\n",
        "    \"\"\"\n",
        "    convert a torch.Tensor to a numpy array-> denormalize (if needed) -> type casting -> writing image to the given path\n",
        "    \"\"\"\n",
        "    # if isinstance(image, torch.Tensor):\n",
        "    #     image = image.numpy()\n",
        "\n",
        "    if denormalize:\n",
        "        image = denormalize_image(image)\n",
        "\n",
        "    #image = image.astype(np.uint8).copy()\n",
        "    image=make_grid(image.cpu().detach(),nrow=int(math.sqrt(image.size(0))))\n",
        "    image=TF.to_pil_image(image)\n",
        "    image.save(save_path)\n",
        "\n",
        "   # cv2.imwrite(save_path, cv2.cvtColor(image.transpose(1,2,0), cv2.COLOR_BGR2RGB))\n",
        "\n",
        "\n",
        "def save_checkpoint(epoch, G, F, D_x, D_y, optim_G, optim_D, scheduler_G, scheduler_D, saved_dir, file_name):\n",
        "    check_point = {'epoch': epoch,\n",
        "                    'G': G.state_dict(),\n",
        "                    'F': F.state_dict(),\n",
        "                    'D_x': D_x.state_dict(),\n",
        "                    'D_y': D_y.state_dict(),\n",
        "                    'optimG_state_dict': optim_G.state_dict(),\n",
        "                    'optimD_state_dict': optim_D.state_dict()\n",
        "                    }\n",
        "    if scheduler_G and scheduler_D:\n",
        "        check_point['scheduler_G_state_dict'] = scheduler_G.state_dict()\n",
        "        check_point['scheduler_D_state_dict'] = scheduler_D.state_dict()\n",
        "\n",
        "    os.makedirs(saved_dir, exist_ok=True) # make a directory to save a model if not exist.\n",
        "\n",
        "    output_path = os.path.join(saved_dir, file_name)\n",
        "    torch.save(check_point, output_path)\n",
        "\n",
        "\n",
        "def load_checkpoint(checkpoint_path, G, F, D_x:Optional[torch.nn.Module]=None, D_y:Optional[torch.nn.Module]=None, \\\n",
        "                    optim_G:Optional[Optimizer]=None, optim_D:Optional[Optimizer]=None, \\\n",
        "                    scheduler_G:Optional[_LRScheduler]=None, scheduler_D:Optional[_LRScheduler]=None, mode:str=\"model\"):\n",
        "    # load model if resume_from is set\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "    G.load_state_dict(checkpoint['G'])\n",
        "    F.load_state_dict(checkpoint['F'])\n",
        "\n",
        "    if D_x and D_y:\n",
        "        D_x.load_state_dict(checkpoint['D_x'])\n",
        "        D_y.load_state_dict(checkpoint['D_y'])\n",
        "\n",
        "    start_epoch = checkpoint['epoch']\n",
        "\n",
        "    if mode == \"model\":\n",
        "        return G, F, D_x, D_y, start_epoch\n",
        "\n",
        "    if mode ==\"all\":\n",
        "        optim_G.load_state_dict(checkpoint['optimG_state_dict'])\n",
        "        optim_D.load_state_dict(checkpoint['optimD_state_dict'])\n",
        "\n",
        "        if scheduler_G and scheduler_D:\n",
        "            scheduler_G.load_state_dict(checkpoint['scheduler_G_state_dict'])\n",
        "            scheduler_D.load_state_dict(checkpoint['scheduler_D_state_dict'])\n",
        "\n",
        "            return G, F, D_x, D_y, optim_G, optim_D, scheduler_G, scheduler_D, start_epoch\n",
        "\n",
        "        return G, F, D_x, D_y, optim_G, optim_D, start_epoch\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"mode should be one of 'model' or 'all'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kCVb9dmw_569",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7689179-1dd3-41e5-98a6-eb63f7854ceb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 49%|████▉     | 56/114 [02:48<02:53,  3.00s/it]"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
        "\n",
        "\n",
        "from sched import scheduler\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# from augmentation_my import BaseAugmentation\n",
        "# from criterion_my import *\n",
        "# from dataset_my import UnalignedDataset\n",
        "# from model_my import *\n",
        "# from utils_my import *\n",
        "# from scheduler_my import DelayedLinearDecayLR\n",
        "\n",
        "from functools import partial\n",
        "import itertools\n",
        "#import os\n",
        "from tqdm import tqdm\n",
        "# import wandb\n",
        "import argparse\n",
        "\n",
        "# opt로 변경하는 작업\n",
        "def train(opt):\n",
        "\n",
        "    os.makedirs(opt.sample_save_dir, exist_ok=True)\n",
        "\n",
        "    # device\n",
        "    device = torch.device(f'cuda:{opt.gpu_id}' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # define transforms\n",
        "    transforms = BaseAugmentation()\n",
        "\n",
        "    # load datasets\n",
        "    train_data = UnalignedDataset(opt.data_root_A, opt.data_root_B, opt.is_train, transforms = transforms.transform)\n",
        "    train_loader = DataLoader(train_data, batch_size=opt.batch_size, num_workers=opt.num_threads, shuffle=True)\n",
        "\n",
        "    # load model\n",
        "    G = Generator(init_channel=64, kernel_size=3, stride=2, n_blocks=9).to(device)\n",
        "    F = Generator(init_channel=64, kernel_size=3, stride=2, n_blocks=9).to(device)\n",
        "    D_x = Discriminator().to(device)\n",
        "    D_y = Discriminator().to(device)\n",
        "\n",
        "    # define optimizer\n",
        "    optimizer = partial(torch.optim.Adam, lr=opt.lr, betas=(opt.beta1, 0.999))\n",
        "\n",
        "    optim_G = optimizer(params = itertools.chain(G.parameters(), F.parameters()))\n",
        "    optim_D = optimizer(params = itertools.chain(D_x.parameters(), D_y.parameters()))\n",
        "\n",
        "    # scheduler\n",
        "    scheduler_G = DelayedLinearDecayLR(optim_G, opt.lr, opt.target_lr, opt.total_iters, decay_after=opt.decay_after, verbose=opt.lr_decay_verbose)\n",
        "    scheduler_D = DelayedLinearDecayLR(optim_D, opt.lr, opt.target_lr, opt.total_iters, decay_after=opt.decay_after, verbose=opt.lr_decay_verbose)\n",
        "\n",
        "\n",
        "    criterion_G = AdversarialLoss()\n",
        "    criterion_D = AdversarialLoss()\n",
        "    criterion_cyc = CycleConsistencyLoss()\n",
        "    criterion_idt = IdentityLoss()\n",
        "\n",
        "    G.train()\n",
        "    F.train()\n",
        "    D_x.train()\n",
        "    D_y.train()\n",
        "\n",
        "    if opt.resume_from:\n",
        "        checkpoint_path = os.path.join(opt.checkpoint_dir, f\"epoch{opt.last_epoch}.pth\")\n",
        "        if \"LinearDecay\" in getattr(type(scheduler_D), '__name__'): # when using LinearDecayLR, not loading state dict for optimizers and schedulers.\n",
        "            G, F, D_x, D_y, start_epoch = load_checkpoint(checkpoint_path, G, F, D_x, D_y)\n",
        "            # decay after 같은 부분 수정하는 건 그냥 config 자체에서 받아오는 걸로 / last epoch만 수정해주자.\n",
        "            scheduler_dict = {\n",
        "                'decay_after': start_epoch + opt.decay_after,\n",
        "                'last_epoch': opt.last_epoch\n",
        "            }\n",
        "            scheduler_G.load_state_dict(scheduler_dict)\n",
        "            scheduler_D.load_state_dict(scheduler_dict)\n",
        "\n",
        "        else:\n",
        "            G, F, D_x, D_y, optim_G, optim_D, scheduler_G, scheduler_D, start_epoch = load_checkpoint(checkpoint_path, G, F, D_x, D_y, \\\n",
        "                                                                                                    optim_G, optim_D, scheduler_G, scheduler_D, mode=\"all\")\n",
        "        start_epoch += 1\n",
        "    else: # not_resume from\n",
        "        start_epoch = 0\n",
        "\n",
        "    for epoch in range(start_epoch, start_epoch+opt.n_epochs):\n",
        "        pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
        "        for step, data in pbar:\n",
        "\n",
        "            # Initialize the gradient stored in the optimizer to zero in the beginning of each step.\n",
        "            optim_G.zero_grad()\n",
        "            optim_D.zero_grad()\n",
        "\n",
        "            # load data on gpu\n",
        "            X, Y = data['A'].to(device), data['B'].to(device)\n",
        "\n",
        "            #### Generator ####\n",
        "            for p_x, p_y in zip(D_x.parameters(), D_y.parameters()): # when optimizing G, freeze the parameters regarding D.\n",
        "                p_x.requires_grad = False\n",
        "                p_y.requires_grad = False\n",
        "\n",
        "            # generation & reconstruction\n",
        "            g_x = G(X) # fake_B\n",
        "            f_y = F(Y) # fake_A\n",
        "            rec_x = F(g_x) # rec_A (reconstruction)\n",
        "            rec_y = G(f_y) # rec_B\n",
        "\n",
        "            # discriminating the generators' outputs.\n",
        "            d_g_x = D_y(g_x)\n",
        "            d_f_y = D_x(f_y)\n",
        "\n",
        "            # generate the label\n",
        "            real_label = torch.tensor([1.0]).expand_as(d_g_x).to(device)\n",
        "            fake_label = torch.tensor([0.0]).expand_as(d_f_y).to(device)\n",
        "\n",
        "            # calculate an adversarial loss -> maximize the probability of the fake to be \"considered\" real\n",
        "            loss_G_xy = criterion_G.forward_G(d_g_x, real_label)\n",
        "            loss_F_yx = criterion_G.forward_G(d_f_y, real_label)\n",
        "\n",
        "            # calc cycle loss\n",
        "            loss_cyc = criterion_cyc(X, Y, rec_x, rec_y)\n",
        "\n",
        "            # calc identity loss if lambda of identity loss larger than zero.\n",
        "            if opt.lambda_idt > 0:\n",
        "                loss_idt = opt.lambda_idt*criterion_idt(X, Y, f_y, g_x)\n",
        "            else: # lambda_idt = 0\n",
        "                loss_idt = 0\n",
        "\n",
        "            loss_G = loss_G_xy + loss_F_yx + opt.lambda_cyc*loss_cyc + opt.lambda_idt*loss_idt\n",
        "\n",
        "            loss_G.backward() # calculate all the gradient with respect to loss_G.\n",
        "            optim_G.step() # alternating training 해야돼서 G랑 D는 optimizer 따로 쓰는 거임.\n",
        "\n",
        "            #### Discriminator ####\n",
        "            for p_x, p_y in zip(D_x.parameters(), D_y.parameters()):\n",
        "                p_x.requires_grad = True\n",
        "                p_y.requires_grad = True\n",
        "\n",
        "            loss_D_xy = criterion_D.forward_D(D_y(Y), real_label, D_y(g_x.detach()), fake_label)\n",
        "            loss_D_yx = criterion_D.forward_D(D_x(X), real_label, D_x(f_y.detach()), fake_label)\n",
        "\n",
        "            # average the loss\n",
        "            loss_D = (loss_D_xy+loss_D_yx)/2\n",
        "\n",
        "            loss_D.backward()\n",
        "            optim_D.step()\n",
        "\n",
        "\n",
        "        # Apply the scheduler (make sure the step of optimizers precede that of schedulers)\n",
        "        scheduler_G.step()\n",
        "        scheduler_D.step()\n",
        "\n",
        "        # saving checkpoints\n",
        "        checkpoint_dir = os.path.join(opt.checkpoint_dir, opt.exp_name)\n",
        "        opt.load_epoch=epoch\n",
        "\n",
        "\n",
        "        best_loss=float(\"inf\")\n",
        "        if loss_cyc.item()<best_loss:\n",
        "            best_loss=loss_cyc.item()\n",
        "            early_stop_counter=0\n",
        "        else:\n",
        "            early_stop_counter+=1\n",
        "        if early_stop_counter>=5:\n",
        "            print(f\"Early stopping at epoch, which is {epoch}\")\n",
        "            break\n",
        "\n",
        "        #if epoch%5==0:\n",
        "        save_checkpoint(epoch, G, F, D_x, D_y, optim_G, optim_D, scheduler_G, scheduler_D, checkpoint_dir, file_name=f\"epoch{epoch+1}.pth\")\n",
        "\n",
        "        # saving sample outputs\n",
        "        if opt.log_interval>0:\n",
        "             save_image(g_x.clone().detach().cpu(), f\"{opt.sample_save_dir}/epoch{epoch+1}_step{step+1}.jpg\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "    opt = parse_opt()\n",
        "\n",
        "    fix_seed(opt.random_seed) # randomness 제어/\n",
        "    train(opt)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G03Z4ZN2gmv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "3QShzVj2__2Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b59b94e8-4dc1-4768-a6f7-317a271d4dcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:01<00:00,  1.56s/it]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "# from augmentation_my import BaseAugmentation\n",
        "# from dataset_my import UnalignedDataset\n",
        "# from model_my import Generator\n",
        "# from utils_my import *\n",
        "\n",
        "import torch\n",
        "#from torch.utils.data import DataLoader\n",
        "\n",
        "def test(test_loader, G, F, device, save_dir,save_dir_XtoY='/content/drive/MyDrive/result/exp1/epoch_final/day2night', save_dir_YtoX='/content/drive/MyDrive/result/exp1/epoch_final/night2day'):\n",
        "    G.to(device)\n",
        "    F.to(device)\n",
        "\n",
        "    G.eval()\n",
        "    F.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pbar = tqdm(enumerate(test_loader), total=len(test_loader))\n",
        "\n",
        "        for step, data in pbar:\n",
        "            X, Y = data['A'], data['B']\n",
        "\n",
        "            X, Y = X.to(device), Y.to(device)\n",
        "\n",
        "            fake_Y = G(X)\n",
        "            fake_X = F(Y)\n",
        "\n",
        "            # make an image array\n",
        "            XY = torch.cat([X, fake_Y, F(fake_Y)], dim = 3) # column-wise concat\n",
        "            YX = torch.cat([Y, fake_X, G(fake_X)], dim = 3)\n",
        "\n",
        "            os.makedirs(f\"{save_dir_XtoY}/\", exist_ok=True)\n",
        "            os.makedirs(f\"{save_dir_YtoX}/\", exist_ok=True)\n",
        "\n",
        "            # array로 저장해서 보는 게 빠를 것 같음. grid로 만들어서 보는 법 찾아볼 것.\n",
        "            save_image(XY.clone().detach().cpu(), f\"{save_dir}/day2night/{step+1}.png\")\n",
        "            save_image(YX.clone().detach().cpu(), f\"{save_dir}/night2day/{step+1}.png\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    opt = parse_opt()\n",
        "\n",
        "    fix_seed(opt.random_seed) # randomness 제어\n",
        "\n",
        "    # device\n",
        "    device = torch.device(f'cuda:{opt.gpu_id}' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # define transforms\n",
        "    transforms = BaseAugmentation()\n",
        "\n",
        "    # load datasets\n",
        "    test_data = UnalignedDataset(opt.data_root_A_final, opt.data_root_B_final, False, transforms = transforms.transform)\n",
        "    test_loader = DataLoader(test_data, batch_size=opt.batch_size, num_workers=opt.num_threads, shuffle=False)\n",
        "\n",
        "    # declare architectures\n",
        "    G = Generator(init_channel=64, kernel_size=3, stride=2, n_blocks=9)\n",
        "    F = Generator(init_channel=64, kernel_size=3, stride=2, n_blocks=9)\n",
        "\n",
        "    G, F, _, _, _ = load_checkpoint(os.path.join(opt.checkpoint_dir,opt.exp_name,f\"epoch{opt.load_epoch+1}.pth\"), G, F)\n",
        "\n",
        "    save_dir = os.path.join(opt.sample_save_dir, opt.exp_name, f\"epoch_final\")\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    test(test_loader, G, F, device, save_dir)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LwkJFb9hX0Jy"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}